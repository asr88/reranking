{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Base del sistema RAG\n",
    "\n",
    "En esta sección se reutiliza el código desarrollado en el tutorial donde se explica cómo construir un sistema RAG básico. No se volverá a explicar cada componente en detalle, ya que esa explicación se encuentra en el tutorial original. El objetivo aquí es establecer la **arquitectura base** que será utilizada como punto de partida para introducir, en secciones posteriores, las técnicas de query rewriting y reranking.\n",
    "\n",
    "El código base incluye:\n",
    "\n",
    "- La carga y segmentación de documentos Markdown utilizando `MarkdownHeaderTextSplitter`, generando chunks semánticamente coherentes con metadatos de trazabilidad.\n",
    "- La creación de un índice FAISS a partir de embeddings generados con modelos de Google y la configuración de un retriever para búsqueda por similitud.\n",
    "\n",
    "En este punto, el sistema se limita a preparar los documentos y a exponer un mecanismo de recuperación estándar. No se realiza todavía ninguna reformulación de la consulta ni se aplica ningún proceso de reordenamiento de los documentos recuperados.\n",
    "\n",
    "⚠️ **Almacenamiento de los documentos**: Los documentos deben estar en una carpeta llamada `data` en la raíz del proyecto. Si utiliza otra estructura, ajuste el parámetro `data_folder` en el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Cargar variables desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Asignar la clave de API a la variable de entorno esperada por el SDK de Google\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Instancia del modelo de embeddings para indexación de los documentos\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "# Instancia del modelo de lenguaje para generación de respuestas\n",
    "language_model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(data_folder=\"data\"):\n",
    "    \"\"\"\n",
    "    Carga todos los documentos Markdown desde la carpeta especificada, aplicando\n",
    "    segmentación basada en estructura de documento (segmentación por encabezados)\n",
    "    para generar chunks semánticamente coherentes, listos para el proceso de\n",
    "    indexación en base de datos vectorial.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Ruta a la carpeta que contiene los archivos Markdown a\n",
    "            cargar y segmentar.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de chunks representados mediante objetos Document con metadatos\n",
    "            básicos para garantizar control y trazabilidad.\n",
    "    \"\"\"\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\")\n",
    "    ]\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=False\n",
    "    )\n",
    "\n",
    "    data_path = Path(data_folder)\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"La carpeta '{data_path}' no existe\")\n",
    "\n",
    "    markdown_files = list(data_path.glob(\"*.md\"))\n",
    "    if not markdown_files:\n",
    "        raise FileNotFoundError(f\"No se encontraron archivos Markdown en la carpeta '{data_path}'\")\n",
    "\n",
    "    all_chunks = []\n",
    "\n",
    "    for file_path in markdown_files:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "        chunks = markdown_splitter.split_text(content)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk.metadata.update({\n",
    "                \"source_file\": file_path.name,\n",
    "                \"chunk_index\": i,\n",
    "                \"size\": len(chunk.page_content)\n",
    "            })\n",
    "\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_retriever(chunks, embeddings_model, k=3):\n",
    "    \"\"\"\n",
    "    Construye un índice vectorial FAISS a partir de los chunks previamente generados\n",
    "    y devuelve un objeto retriever configurado para realizar búsquedas por\n",
    "    similitud semántica.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): Lista de objetos Document que representan los fragmentos de texto\n",
    "            segmentado a partir de los documentos fuente.\n",
    "        embeddings_model: Modelo de embeddings utilizado para transformar texto en\n",
    "            representaciones vectoriales.\n",
    "        k (int): Número de documentos más similares que se recuperarán durante cada consulta.\n",
    "\n",
    "    Returns:\n",
    "        BaseRetriever: Objeto retriever listo para ser utilizado dentro del flujo RAG.\n",
    "    \"\"\"\n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "    metadatas = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    vectorstore = FAISS.from_texts(\n",
    "        texts=texts,\n",
    "        embedding=embeddings_model,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "\n",
    "    vectorstore.save_local(\"./faiss_index\")\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y segmentar los documentos de entrada\n",
    "chunks = load_documents()\n",
    "print(f\"Se cargaron {len(chunks)} chunks en total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el índice FAISS y el retriever (ejecutar después de tener chunks)\n",
    "retriever = build_faiss_retriever(chunks, embeddings_model, k=3)\n",
    "print(\"Retriever configurado. Índice guardado en ./faiss_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
