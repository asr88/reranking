{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reranking de documentos en sistemas RAG\n",
    "\n",
    "La recuperación inicial se basa en similitud entre embeddings: la relevancia se calcula de forma **independiente** (query y cada documento por separado). El **reranking** añade una segunda etapa: toma los candidatos del retriever y los reordena con un modelo que evalúa **pares (consulta, documento)** de forma conjunta, para quedarse solo con los más relevantes.\n",
    "\n",
    "Se aplica **después** de la recuperación y **antes** de la generación de la respuesta. Los **cross-encoders** son adecuados aquí porque solo se aplican a un número reducido de documentos (p. ej. 10), donde la precisión importa más que la escalabilidad.\n",
    "\n",
    "⚠️ **Requisito**: Ejecute antes el notebook `03_rag_base.ipynb` para generar la carpeta `faiss_index`. Este notebook carga ese índice y crea un retriever con `k=10` para la etapa de reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from sentence_transformers import CrossEncoder\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "# Cargar índice FAISS creado en el notebook 03 y crear retriever con k=10 (más candidatos para reranking)\n",
    "vectorstore = FAISS.load_local(\"./faiss_index\", embeddings_model, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "print(\"Retriever configurado con k=10.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del reranker local\n",
    "\n",
    "Se utiliza un **cross-encoder** de `sentence-transformers` (modelo liviano entrenado sobre MS MARCO) para evaluar pares (query, documento) y asignar un puntaje de relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_reranker(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"):\n",
    "    \"\"\"\n",
    "    Crea y devuelve un modelo CrossEncoder para realizar reranking local\n",
    "    de documentos previamente recuperados.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Nombre o ruta del modelo cross-encoder. Por defecto\n",
    "            un modelo liviano optimizado para búsqueda semántica.\n",
    "\n",
    "    Returns:\n",
    "        CrossEncoder: Instancia del modelo lista para el proceso de reranking.\n",
    "    \"\"\"\n",
    "    cross_encoder = CrossEncoder(model_name)\n",
    "    print(f\"Reranker: {model_name}\")\n",
    "    return cross_encoder\n",
    "\n",
    "cross_encoder = create_local_reranker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de reranking\n",
    "\n",
    "Reordena los documentos recuperados según el puntaje del cross-encoder y devuelve los `n` más relevantes (`n` debe ser menor que el `k` usado en el retriever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_documents(reranker, question, retrieved_docs, n=3, debug=False):\n",
    "    \"\"\"\n",
    "    Reordena los documentos recuperados usando un cross-encoder y devuelve\n",
    "    los n más relevantes respecto a la pregunta.\n",
    "\n",
    "    Args:\n",
    "        reranker: Modelo cross-encoder para relevancia (query, documento).\n",
    "        question (str): Pregunta del usuario.\n",
    "        retrieved_docs (list): Documentos devueltos por el retriever.\n",
    "        n (int): Número de documentos finales a retornar.\n",
    "        debug (bool): Si True, imprime puntajes por documento.\n",
    "\n",
    "    Returns:\n",
    "        list: Los n documentos más relevantes, ordenados de mayor a menor puntaje.\n",
    "    \"\"\"\n",
    "    pairs = [(question, doc.page_content) for doc in retrieved_docs]\n",
    "    scores = reranker.predict(pairs)\n",
    "    scored_docs = list(zip(retrieved_docs, scores))\n",
    "    reranked = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\nPUNTAJES ASIGNADOS POR EL RERANKER:\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (doc, score) in enumerate(reranked, 1):\n",
    "            file = doc.metadata.get(\"source_file\", \"unknown\")\n",
    "            preview = doc.page_content[:60].replace(\"\\n\", \" \")\n",
    "            print(f\"\\n{i}. [{file}] '{preview}...'\")\n",
    "            print(f\"   Relevance score: {score:.4f}\")\n",
    "        print(\"\\n\" + \"-\" * 40)\n",
    "\n",
    "    return [doc for doc, _ in reranked[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demostración del proceso de reranking\n",
    "\n",
    "Se ejecuta una consulta: el retriever devuelve 10 candidatos y el reranker los reordena y filtra a los más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_reranker(retriever, reranker, query):\n",
    "    \"\"\"\n",
    "    Ejecuta búsqueda con el retriever, aplica reranking y muestra los documentos\n",
    "    finales ordenados por relevancia.\n",
    "\n",
    "    Args:\n",
    "        retriever: Retriever configurado (p. ej. FAISS con k=10).\n",
    "        reranker: Modelo cross-encoder para reranking.\n",
    "        query (str): Consulta de ejemplo.\n",
    "    \"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    reranked_docs = rerank_documents(reranker, query, docs, n=3, debug=True)\n",
    "\n",
    "    print(\"\\nRESULTADOS RETRIEVER + RERANKER:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nConsulta: '{query}'\")\n",
    "    print(f\"Documentos finales: {len(reranked_docs)}\")\n",
    "    for i, doc in enumerate(reranked_docs, 1):\n",
    "        file = doc.metadata.get(\"source_file\", \"unknown\")\n",
    "        preview = doc.page_content[:60].replace(\"\\n\", \" \")\n",
    "        print(f\"\\n  {i}. {file}: '{preview}...'\")\n",
    "    print(\"\\n\" + \"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_reranker(retriever, cross_encoder, \"¿Qué prácticas ayudan a mejorar la robustez del manejo de errores y autenticación en APIs?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
